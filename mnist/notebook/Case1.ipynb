{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Case1Assignment5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I15lmaTbHKYM"
      },
      "source": [
        "Target:\n",
        "\n",
        "Basic Network. \n",
        "Results:\n",
        "\n",
        "16k Parameters\n",
        "\n",
        "Best Train Accuracy: 99.26\n",
        "\n",
        "Best Test Accuracy: 98.92\n",
        "\n",
        "Observations:\n",
        "\n",
        "1. Model has decent parameters\n",
        "2. Overfitting can be seen happening after epoch 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m2JWFliFfKT"
      },
      "source": [
        "\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import itertools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_Cx9q2QFgM7"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(1, 8, 3))\n",
        "        self.conv2= nn.Sequential(nn.Conv2d(8, 8, 3))\n",
        "        self.conv3= nn.Sequential(nn.MaxPool2d(2, 2),nn.Conv2d(8, 16, 1))\n",
        "        self.conv4 = nn.Sequential(nn.Conv2d(16, 16, 3))\n",
        "        self.conv5 = nn.Sequential(nn.Conv2d(16, 16, 3))\n",
        "        self.conv6 = nn.Sequential(nn.MaxPool2d(2, 2),nn.Conv2d(16, 32, 1))\n",
        "        self.conv7 = nn.Sequential(nn.Conv2d(32, 32, 3))\n",
        "        self.conv8= nn.Sequential(nn.Conv2d(32, 10, 2))\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = F.relu(self.conv6(x))\n",
        "        x = F.relu(self.conv7(x))\n",
        "        x = self.conv8(x)\n",
        "\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x, dim=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdydjYTZFyi3",
        "outputId": "09dcd164-e938-41c7-8b7c-30e8567fd629"
      },
      "source": [
        "#!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 26, 26]              80\n",
            "            Conv2d-2            [-1, 8, 24, 24]             584\n",
            "         MaxPool2d-3            [-1, 8, 12, 12]               0\n",
            "            Conv2d-4           [-1, 16, 12, 12]             144\n",
            "            Conv2d-5           [-1, 16, 10, 10]           2,320\n",
            "            Conv2d-6             [-1, 16, 8, 8]           2,320\n",
            "         MaxPool2d-7             [-1, 16, 4, 4]               0\n",
            "            Conv2d-8             [-1, 32, 4, 4]             544\n",
            "            Conv2d-9             [-1, 32, 2, 2]           9,248\n",
            "           Conv2d-10             [-1, 10, 1, 1]           1,290\n",
            "================================================================\n",
            "Total params: 16,530\n",
            "Trainable params: 16,530\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.13\n",
            "Params size (MB): 0.06\n",
            "Estimated Total Size (MB): 0.20\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqTWLaM5GHgH"
      },
      "source": [
        "torch.manual_seed(1)\n",
        "batch_size = 128\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.RandomRotation(5),      \n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "source": [
        "from tqdm import tqdm\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    train_correct = 0\n",
        "    loss = 0\n",
        "    model.train()\n",
        "    for data, target in train_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pred = output.argmax(dim=1, keepdim=True) \n",
        "        train_correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "    loss, train_correct, len(train_loader.dataset),\n",
        "    100. * train_correct / len(train_loader.dataset)))\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  \n",
        "            pred = output.argmax(dim=1, keepdim=True) \n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMWbLWO6FuHb",
        "outputId": "af765db1-2b0f-422f-b597-2c6eba2ebb7e"
      },
      "source": [
        "\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "no_of_epochs = 15\n",
        "for epoch in range(no_of_epochs):\n",
        "    print(\"Epoch Number :=> \",epoch+1)\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch Number :=>  1\n",
            "\n",
            "Train set: Average loss: 0.0000, Accuracy: 31403/60000 (52.34%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.1623, Accuracy: 9495/10000 (94.95%)\n",
            "\n",
            "Epoch Number :=>  2\n",
            "\n",
            "Train set: Average loss: 0.0000, Accuracy: 57450/60000 (95.75%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0811, Accuracy: 9750/10000 (97.50%)\n",
            "\n",
            "Epoch Number :=>  3\n",
            "\n",
            "Train set: Average loss: 0.0000, Accuracy: 58356/60000 (97.26%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0688, Accuracy: 9776/10000 (97.76%)\n",
            "\n",
            "Epoch Number :=>  4\n",
            "\n",
            "Train set: Average loss: 0.0000, Accuracy: 58696/60000 (97.83%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0543, Accuracy: 9819/10000 (98.19%)\n",
            "\n",
            "Epoch Number :=>  5\n",
            "\n",
            "Train set: Average loss: 0.0000, Accuracy: 58846/60000 (98.08%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0538, Accuracy: 9831/10000 (98.31%)\n",
            "\n",
            "Epoch Number :=>  6\n",
            "\n",
            "Train set: Average loss: 0.0000, Accuracy: 59023/60000 (98.37%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0391, Accuracy: 9871/10000 (98.71%)\n",
            "\n",
            "Epoch Number :=>  7\n",
            "\n",
            "Train set: Average loss: 0.0000, Accuracy: 59110/60000 (98.52%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0433, Accuracy: 9856/10000 (98.56%)\n",
            "\n",
            "Epoch Number :=>  8\n",
            "\n",
            "Train set: Average loss: 0.0000, Accuracy: 59206/60000 (98.68%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0406, Accuracy: 9867/10000 (98.67%)\n",
            "\n",
            "Epoch Number :=>  9\n",
            "\n",
            "Train set: Average loss: 0.0000, Accuracy: 59297/60000 (98.83%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0354, Accuracy: 9882/10000 (98.82%)\n",
            "\n",
            "Epoch Number :=>  10\n",
            "\n",
            "Train set: Average loss: 0.0000, Accuracy: 59339/60000 (98.90%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0323, Accuracy: 9886/10000 (98.86%)\n",
            "\n",
            "Epoch Number :=>  11\n",
            "\n",
            "Train set: Average loss: 0.0000, Accuracy: 59368/60000 (98.95%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0360, Accuracy: 9880/10000 (98.80%)\n",
            "\n",
            "Epoch Number :=>  12\n",
            "\n",
            "Train set: Average loss: 0.0000, Accuracy: 59421/60000 (99.03%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0357, Accuracy: 9873/10000 (98.73%)\n",
            "\n",
            "Epoch Number :=>  13\n",
            "\n",
            "Train set: Average loss: 0.0000, Accuracy: 59481/60000 (99.14%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0354, Accuracy: 9886/10000 (98.86%)\n",
            "\n",
            "Epoch Number :=>  14\n",
            "\n",
            "Train set: Average loss: 0.0000, Accuracy: 59457/60000 (99.09%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0326, Accuracy: 9892/10000 (98.92%)\n",
            "\n",
            "Epoch Number :=>  15\n",
            "\n",
            "Train set: Average loss: 0.0000, Accuracy: 59557/60000 (99.26%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0353, Accuracy: 9887/10000 (98.87%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So5uk4EkHW6R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}