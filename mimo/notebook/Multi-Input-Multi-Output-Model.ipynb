{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b67d9f9",
   "metadata": {},
   "source": [
    "## Create a network which can take in a MNIST Data image and a Random number and output the digit from image and sum of this digit and random number entered\n",
    "\n",
    "![problem modal](./assign.png \"Problem Statement Exmple Modal\")\n",
    "\n",
    "1. the \"number\" that was represented by the MNIST image, and\n",
    "2. the \"sum\" of this number with the random number that was generated and sent as the input to the network\n",
    "3. you can mix fully connected layers and convolution layers\n",
    "4. you can use one-hot encoding to represent the random number input as well as the \"summed\" output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfe0418",
   "metadata": {},
   "source": [
    "### Import All Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4210e4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e70192f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba0ba50",
   "metadata": {},
   "source": [
    "### Design Multi Input Multi Output Network\n",
    "\n",
    "1. This net should take in two inputs, \n",
    "    a. Mnist image (1, 28, 28)\n",
    "    b. Random vector as one hot encoded (1, 10)\n",
    "2. Output two vectors\n",
    "    a. Predicted logits for MNIST digit (1, 10)\n",
    "    b. Predicted logist for sum of both numbers (1, 19)\n",
    "    \n",
    "#### Methodology\n",
    "1. Input image is first passed on to a convolution layer\n",
    "2. Input number as a one hot encoder is passed on to fc layer with output sixe equal to outputsize of first convlayer\n",
    "3. Now the output from above two layers is concatinated in a way that this fc layer output becomes one of the channel\n",
    "4. Further convolution is performed\n",
    "5. In the output just bfore the last layer the output from previous layer is flattered and fed to linear layer with respective output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7bd10f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIMO(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MIMO, self).__init__()\n",
    "        # Input 1\n",
    "        self.conv1 = nn.Conv2d(1, 7, 3)\n",
    "        # Input 2\n",
    "        self.fc1 = nn.Linear(10, 1*26*26)\n",
    "        \n",
    "        # Model\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.conv4 = nn.Conv2d(32, 64, 3)\n",
    "        \n",
    "        # Output Layer\n",
    "        self.fc2 = nn.Linear(64*3*3, 10)\n",
    "        self.fc3 = nn.Linear(64*3*3, 19)\n",
    "        \n",
    "        \n",
    "    def forward(self, im, ra):\n",
    "        x1 = self.conv1(im)\n",
    "        x2 = self.fc1(ra)\n",
    "        \n",
    "        # Concatinate\n",
    "        x = torch.cat((x1, x2.view(-1, 1, 26, 26)), dim=1)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.view(-1, 64*3*3)\n",
    "        \n",
    "        o1 = self.fc2(x)\n",
    "        o2 = self.fc3(x)\n",
    "        \n",
    "        return F.log_softmax(o1, dim = 1), F.log_softmax(o2, dim = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c9cff1",
   "metadata": {},
   "source": [
    "```\n",
    "----------------------------------------------------------------\n",
    "        Layer (type)               Output Shape         Param #\n",
    "================================================================\n",
    "            Conv2d-1            [-1, 7, 26, 26]              70\n",
    "            Linear-2               [-1, 1, 676]           7,436\n",
    "            Conv2d-3           [-1, 16, 24, 24]           1,168\n",
    "         MaxPool2d-4           [-1, 16, 12, 12]               0\n",
    "       BatchNorm2d-5           [-1, 16, 12, 12]              32\n",
    "            Conv2d-6           [-1, 32, 10, 10]           4,640\n",
    "         MaxPool2d-7             [-1, 32, 5, 5]               0\n",
    "       BatchNorm2d-8             [-1, 32, 5, 5]              64\n",
    "            Conv2d-9             [-1, 64, 3, 3]          18,496\n",
    "           Linear-10                   [-1, 10]           5,770\n",
    "           Linear-11                   [-1, 19]          10,963\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8144bf",
   "metadata": {},
   "source": [
    "### Dataset Creation\n",
    "Here we have created a custom dataset, whch spits four values image, im_label, random_number, sum \\[(1, 28, 28), (1, 1), (1, 19), (1, 1) \\]\n",
    "\n",
    "1. Download Raw dataset from MNIST website\n",
    "2. Define a cutom dataset function\n",
    "3. Load dataset as pandas dataframe\n",
    "4. Create a data list from dataframe with these pixels and reshape them to (28, 28, 1)\n",
    "5. Add function __getitem__ , this function will first load image from list, generate a new random number, create onehot vctor for that and then return them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37b6bc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistAndRandomNumberDataset(Dataset):\n",
    "    def __init__(self, transforms=None):\n",
    "        self.img_dim = (28, 28)\n",
    "        self.transforms = transforms\n",
    "        self.idata = []\n",
    "        self.ilabel = []\n",
    "        \n",
    "        # Read Dataset\n",
    "        df = pd.read_csv(\"archive/mnist_784.csv\")\n",
    "        \n",
    "        # Get Labels\n",
    "        self.ilabel = list(df[\"class\"])\n",
    "        \n",
    "        # Drop Labels from DataFrame\n",
    "        df.drop(\"class\", 1, inplace=True)\n",
    "        \n",
    "        # Convert data to np array\n",
    "        self.idata = np.array(df.values.tolist()).reshape(70000, self.img_dim[0], self.img_dim[1], 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Read Image and Label\n",
    "        im = self.idata[idx]\n",
    "        label = self.ilabel[idx]\n",
    "        # Convert label to tensor\n",
    "        label = torch.tensor(label)\n",
    "        \n",
    "        # Apply Transforms\n",
    "        if self.transforms is not None:\n",
    "            im = self.transforms(im)\n",
    "        im = im.to(torch.float)\n",
    "        \n",
    "        # Create random input\n",
    "        rval = torch.randint(0, 9, (1,))[0]\n",
    "\n",
    "        # Convert class id to tensor\n",
    "        rlabel = label + rval\n",
    "        \n",
    "        # Convert value to one hot\n",
    "        rval = F.one_hot(rval, num_classes=10).to(torch.float)\n",
    "\n",
    "        return (im, label, rval, rlabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5349d273",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "1. Split dataset into train and test (80/20)\n",
    "2. Create Loaded with respective splits and enable shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cbb0d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Define transform for conbverting image to tensor before it can be fed to network\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = MnistAndRandomNumberDataset(transforms=transform)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "## Create Data Loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bc3725",
   "metadata": {},
   "source": [
    "#### Visualize Dataset\n",
    "Print some random samples to see how images from our dataset looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "355fea96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print Random Samples\n",
    "for imgs, labels, rvs, rlabels in train_loader:\n",
    "    fig = plt.figure(figsize = (10, 5))\n",
    "    for i in range(8):\n",
    "        ax = fig.add_subplot(2, 4, i + 1, xticks = [], yticks = [])     \n",
    "        plt.imshow(imgs[i].numpy().transpose(1, 2, 0))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457d5e36",
   "metadata": {},
   "source": [
    "### Training\n",
    "1. Define train loop\n",
    "2. Define test loop\n",
    "\n",
    "#### Loss Calculation \n",
    "In out backpropogation we are using **negative log likelihood loss**. `nll_loss`, _`F.nll_loss`_  for a multi-class classification use case the model output is expected to contain log probabilities (applied F.log_softmax as the last activation function on the output) and have the shape \\[batch_size, nb_classes\\]. The target should be a LongTensor in the shape \\[batch_size\\] and should contain the class indices in the range \\[0, nb_classes-1\\].\n",
    "For More Details Refer [Here](https://medium.com/@bhardwajprakarsh/negative-log-likelihood-loss-why-do-we-use-it-for-binary-classification-7625f9e3c944)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca9795e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, scheduler, epoch, device):\n",
    "    model.train()\n",
    "    iepoch_loss = 0\n",
    "    icorrect = 0\n",
    "    repoch_loss = 0\n",
    "    rcorrect = 0\n",
    "    for idata, itarget, rdata, rtarget in train_loader:\n",
    "        idata, itarget, rdata, rtarget = idata.to(device), itarget.to(device), rdata.to(device), rtarget.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        ioutput, routput = model(idata, rdata)\n",
    "        \n",
    "        iloss = F.nll_loss(ioutput, itarget)\n",
    "        rloss = F.nll_loss(routput, rtarget)\n",
    "        loss = iloss + rloss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        ipred = ioutput.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "        icorrect += ipred.eq(itarget.view_as(ipred)).sum().item()\n",
    "        iepoch_loss += iloss.item()\n",
    "        \n",
    "        rpred = routput.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "        rcorrect += rpred.eq(rtarget.view_as(rpred)).sum().item()\n",
    "        repoch_loss += rloss.item()\n",
    "      \n",
    "    return iepoch_loss / len(train_loader), icorrect, repoch_loss / len(train_loader), rcorrect\n",
    "\n",
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    itest_loss = 0\n",
    "    icorrect = 0\n",
    "    rtest_loss = 0\n",
    "    rcorrect = 0\n",
    "    with torch.no_grad():\n",
    "        for idata, itarget, rdata, rtarget in test_loader:\n",
    "            idata, itarget, rdata, rtarget = idata.to(device), itarget.to(device), rdata.to(device), rtarget.to(device)\n",
    "            ioutput, routput = model(idata, rdata)\n",
    "            \n",
    "            itest_loss += F.nll_loss(ioutput, itarget, reduction='sum').item()  # sum up batch loss\n",
    "            ipred = ioutput.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            icorrect += ipred.eq(itarget.view_as(ipred)).sum().item()\n",
    "            \n",
    "            rtest_loss += F.nll_loss(routput, rtarget, reduction='sum').item()  # sum up batch loss\n",
    "            rpred = routput.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            rcorrect += rpred.eq(rtarget.view_as(rpred)).sum().item()\n",
    "\n",
    "    itest_loss /= len(test_loader.dataset)\n",
    "    rtest_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    return itest_loss, icorrect, rtest_loss, rcorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "463f8978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cuda\n",
      "Epochs: 10\n",
      "Lr: 0.0005\n",
      "Max Lr: 0.001\n",
      "Batch Size: 64\n",
      "\n",
      "\n",
      "Epoch: 01\n",
      "\t   Learning Rate: 0.000040\n",
      "\t            Time: 0m 7s\n",
      "\t    I Train Loss: 0.618901     |  R Train Loss: 2.533642\n",
      "\tI Train Accuracy: 48029/56000  |  Percent: 86%\n",
      "\tR Train Accuracy:  5919/56000  |  Percent: 11%\n",
      "\t     I Val. Loss: 0.114003     |  R Val. Loss: 2.386915\n",
      "\t  I Val Accuracy: 13562/14000  |  Percent: 97%\n",
      "\t  R Val Accuracy:  1541/14000  |  Percent: 11%\n",
      "Epoch: 02\n",
      "\t   Learning Rate: 0.000360\n",
      "\t            Time: 0m 6s\n",
      "\t    I Train Loss: 0.095886     |  R Train Loss: 1.979420\n",
      "\tI Train Accuracy: 54439/56000  |  Percent: 97%\n",
      "\tR Train Accuracy: 13817/56000  |  Percent: 25%\n",
      "\t     I Val. Loss: 0.090247     |  R Val. Loss: 1.202095\n",
      "\t  I Val Accuracy: 13583/14000  |  Percent: 97%\n",
      "\t  R Val Accuracy:  7678/14000  |  Percent: 55%\n",
      "Epoch: 03\n",
      "\t   Learning Rate: 0.000680\n",
      "\t            Time: 0m 6s\n",
      "\t    I Train Loss: 0.077516     |  R Train Loss: 0.514355\n",
      "\tI Train Accuracy: 54690/56000  |  Percent: 98%\n",
      "\tR Train Accuracy: 47342/56000  |  Percent: 85%\n",
      "\t     I Val. Loss: 0.058659     |  R Val. Loss: 0.211830\n",
      "\t  I Val Accuracy: 13735/14000  |  Percent: 98%\n",
      "\t  R Val Accuracy: 13187/14000  |  Percent: 94%\n",
      "Epoch: 04\n",
      "\t   Learning Rate: 0.001000\n",
      "\t            Time: 0m 6s\n",
      "\t    I Train Loss: 0.057481     |  R Train Loss: 0.151642\n",
      "\tI Train Accuracy: 55044/56000  |  Percent: 98%\n",
      "\tR Train Accuracy: 53611/56000  |  Percent: 96%\n",
      "\t     I Val. Loss: 0.051806     |  R Val. Loss: 0.117659\n",
      "\t  I Val Accuracy: 13758/14000  |  Percent: 98%\n",
      "\t  R Val Accuracy: 13538/14000  |  Percent: 97%\n",
      "Epoch: 05\n",
      "\t   Learning Rate: 0.000857\n",
      "\t            Time: 0m 6s\n",
      "\t    I Train Loss: 0.041209     |  R Train Loss: 0.101974\n",
      "\tI Train Accuracy: 55290/56000  |  Percent: 99%\n",
      "\tR Train Accuracy: 54353/56000  |  Percent: 97%\n",
      "\t     I Val. Loss: 0.042700     |  R Val. Loss: 0.079670\n",
      "\t  I Val Accuracy: 13807/14000  |  Percent: 99%\n",
      "\t  R Val Accuracy: 13677/14000  |  Percent: 98%\n",
      "Epoch: 06\n",
      "\t   Learning Rate: 0.000714\n",
      "\t            Time: 0m 7s\n",
      "\t    I Train Loss: 0.034248     |  R Train Loss: 0.081467\n",
      "\tI Train Accuracy: 55390/56000  |  Percent: 99%\n",
      "\tR Train Accuracy: 54674/56000  |  Percent: 98%\n",
      "\t     I Val. Loss: 0.039359     |  R Val. Loss: 0.077836\n",
      "\t  I Val Accuracy: 13838/14000  |  Percent: 99%\n",
      "\t  R Val Accuracy: 13691/14000  |  Percent: 98%\n",
      "Epoch: 07\n",
      "\t   Learning Rate: 0.000571\n",
      "\t            Time: 0m 7s\n",
      "\t    I Train Loss: 0.027736     |  R Train Loss: 0.064755\n",
      "\tI Train Accuracy: 55508/56000  |  Percent: 99%\n",
      "\tR Train Accuracy: 54929/56000  |  Percent: 98%\n",
      "\t     I Val. Loss: 0.035879     |  R Val. Loss: 0.067051\n",
      "\t  I Val Accuracy: 13839/14000  |  Percent: 99%\n",
      "\t  R Val Accuracy: 13706/14000  |  Percent: 98%\n",
      "Epoch: 08\n",
      "\t   Learning Rate: 0.000428\n",
      "\t            Time: 0m 7s\n",
      "\t    I Train Loss: 0.021627     |  R Train Loss: 0.054633\n",
      "\tI Train Accuracy: 55634/56000  |  Percent: 99%\n",
      "\tR Train Accuracy: 55060/56000  |  Percent: 98%\n",
      "\t     I Val. Loss: 0.032926     |  R Val. Loss: 0.065013\n",
      "\t  I Val Accuracy: 13852/14000  |  Percent: 99%\n",
      "\t  R Val Accuracy: 13720/14000  |  Percent: 98%\n",
      "Epoch: 09\n",
      "\t   Learning Rate: 0.000286\n",
      "\t            Time: 0m 7s\n",
      "\t    I Train Loss: 0.016806     |  R Train Loss: 0.045707\n",
      "\tI Train Accuracy: 55695/56000  |  Percent: 99%\n",
      "\tR Train Accuracy: 55248/56000  |  Percent: 99%\n",
      "\t     I Val. Loss: 0.030859     |  R Val. Loss: 0.056470\n",
      "\t  I Val Accuracy: 13858/14000  |  Percent: 99%\n",
      "\t  R Val Accuracy: 13761/14000  |  Percent: 98%\n",
      "Epoch: 10\n",
      "\t   Learning Rate: 0.000143\n",
      "\t            Time: 0m 7s\n",
      "\t    I Train Loss: 0.013922     |  R Train Loss: 0.039564\n",
      "\tI Train Accuracy: 55760/56000  |  Percent: 100%\n",
      "\tR Train Accuracy: 55328/56000  |  Percent: 99%\n",
      "\t     I Val. Loss: 0.029102     |  R Val. Loss: 0.048545\n",
      "\t  I Val Accuracy: 13867/14000  |  Percent: 99%\n",
      "\t  R Val Accuracy: 13791/14000  |  Percent: 99%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "model = MIMO().to(device)\n",
    "\n",
    "# Train Params\n",
    "epochs = 10\n",
    "lr = 0.0005\n",
    "max_lr = 0.001\n",
    "steps_per_epoch=len(train_loader)\n",
    "\n",
    "print(\"Using Device:\", device)\n",
    "print(\"Epochs:\", epochs)\n",
    "print(\"Lr:\", lr)\n",
    "print(\"Max Lr:\", max_lr)\n",
    "print(\"Batch Size:\", batch_size)\n",
    "print(\"\\n\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=max_lr, steps_per_epoch=steps_per_epoch, epochs=epochs, anneal_strategy='linear')\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch: {epoch+1:02}')\n",
    "    print(f'\\t   Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    itrain_loss, itrain_correct, rtrain_loss, rtrain_correct = train(model, train_loader, optimizer, scheduler, epoch, device)\n",
    "    ivalid_loss, ivalid_correct, rvalid_loss, rvalid_correct = test(model, test_loader, device)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'\\t            Time: {epoch_mins}m {epoch_secs}s');\n",
    "    print(f'\\t    I Train Loss: {itrain_loss:.6f}     |  R Train Loss: {rtrain_loss:.6f}')\n",
    "    print(f'\\tI Train Accuracy: {itrain_correct:5d}/{len(train_loader.dataset):5d}  |  Percent: {(100. * itrain_correct / len(train_loader.dataset)):.0f}%')\n",
    "    print(f'\\tR Train Accuracy: {rtrain_correct:5d}/{len(train_loader.dataset):5d}  |  Percent: {(100. * rtrain_correct / len(train_loader.dataset)):.0f}%')\n",
    "    print(f'\\t     I Val. Loss: {ivalid_loss:.6f}     |  R Val. Loss: {rvalid_loss:.6f}')\n",
    "    print(f'\\t  I Val Accuracy: {ivalid_correct:5d}/{len(test_loader.dataset):5d}  |  Percent: {(100. * ivalid_correct / len(test_loader.dataset)):.0f}%')\n",
    "    print(f'\\t  R Val Accuracy: {rvalid_correct:5d}/{len(test_loader.dataset):5d}  |  Percent: {(100. * rvalid_correct / len(test_loader.dataset)):.0f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb6aa1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastapi-skelaton",
   "language": "python",
   "name": "fastapi-skelaton"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}